{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grail.fairness.data.metrics\n",
    "\n",
    "> This module contains functions for computing fairness metrics for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp fairness.data.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "from grail.fairness.data.utils import remark_spiel_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>loan_application_date</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>feature_x</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>ggives</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>loc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>gloan</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>loc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>gcredit</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>loc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>gcredit</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>loc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>borrowload</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>loc2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age loan_application_date   loan_type  feature_x  target  gender  \\\n",
       "0   0   48            2013-05-18      ggives         97       1  female   \n",
       "1   1   53            2015-01-01       gloan         29       1    male   \n",
       "2   2   28            2016-02-26     gcredit         76       1    male   \n",
       "3   3   58            2014-03-05     gcredit         43       1    male   \n",
       "4   4   27            2015-01-25  borrowload         57       1    male   \n",
       "\n",
       "  location  \n",
       "0     loc3  \n",
       "1     loc2  \n",
       "2     loc1  \n",
       "3     loc3  \n",
       "4     loc2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from grail.fairness.data.utils import create_biased_dataset\n",
    "\n",
    "df = create_biased_dataset(100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance\n",
    "\n",
    "Class imbalance (CI) bias occurs when a class value *d* has fewer training samples when compared with another class value *a* in the dataset. We call the class with fewer values the **disadvantaged class or the risk group** while the class with more training samples as the **advantaged class**. This is because models preferentially fit the larger classes at the expense of the smaller classes and so can result in a higher training error for class *d*. Models are also at higher risk of overfitting the smaller data sets, which can cause a larger test error for class *d*. Consider the example where a machine learning model is trained primarily on data from middle-aged individuals (class *a*), it might be less accurate when making predictions involving younger and older people (class *d*).\n",
    "\n",
    "The formula for the (normalized) facet imbalance measure:\n",
    "\n",
    "$$CI = (n_a - n_d)/(n_a + n_d)$$\n",
    "\n",
    "Where $n_a$ is the number of members of the advantaged class and $n_d$ the number for the disadvantaged class. Its values range over the interval [-1, 1].\n",
    "\n",
    "**Note:** If a feature is multi-class, the disadvantaged class is computed against the number of all the other classes: $n_d = n_1 + n_2 + n_n$\n",
    "\n",
    "- Positive values indicate the advantaged class has more training samples in the dataset.\n",
    "- Values near zero indicate the classes are balanced in the number of training samples in the dataset.\n",
    "- Negative values indicate the disadvantaged class has more training samples in the dataset.\n",
    "\n",
    "\n",
    "Document Source: [AWS Clarify][AWS Clarify]<br>\n",
    "Code Inspiration: [Medium][Medium]\n",
    "\n",
    "[AWS Clarify]: https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-bias-metric-class-imbalance.html\n",
    "[Medium]: https://medium.com/@corymaklin/pretraining-data-bias-18e1d1dfc350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def compute_class_imbalance(num_class_adv: int, num_class_disadv: int) -> float:\n",
    "    \"\"\"\n",
    "    Compute class imbalance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_class_adv\n",
    "        number of records for the advantaged class\n",
    "    num_class_disadv\n",
    "        number of records for the disadvantaged class\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    class_imbalance_value\n",
    "        The class imbalance metric\n",
    "    \"\"\"\n",
    "    metric_value = (num_class_adv - num_class_disadv) / (\n",
    "        num_class_adv + num_class_disadv\n",
    "    )\n",
    "    return metric_value\n",
    "\n",
    "\n",
    "def class_imbalance(\n",
    "    df: pd.DataFrame,\n",
    "    protected_feature: str,\n",
    "    underpriviledged_group: str = None,\n",
    "    threshold: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute class imbalance given a pandas series containing a categorical feature column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_col\n",
    "        the feature column with the advantaged and disadvantaged class\n",
    "    underpriviledged_group\n",
    "        optional. the disadvantaged class\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The class imbalance metric\n",
    "    \"\"\"\n",
    "    METRIC_NAME = \"class_imbalance\"\n",
    "    df_col = df[protected_feature]\n",
    "    if underpriviledged_group:\n",
    "        underpriviledged_group = [underpriviledged_group]\n",
    "    else:\n",
    "        underpriviledged_group = df_col.unique()\n",
    "\n",
    "    num_class = df_col.value_counts().to_dict()\n",
    "    num_results = len(underpriviledged_group)\n",
    "    metric_vals = []\n",
    "    exceeds_thredhold = []\n",
    "    remarks = []\n",
    "    for val in underpriviledged_group:\n",
    "        num_class_disadv = num_class[val]\n",
    "        num_class_adv = len(df_col) - num_class_disadv\n",
    "        metric_val = compute_class_imbalance(num_class_adv, num_class_disadv)\n",
    "        exceeds_flag = (\n",
    "            True if metric_val > threshold or metric_val < -threshold else False\n",
    "        )\n",
    "        remarks.append(\n",
    "            remark_spiel_generator(\n",
    "                feature_name=protected_feature,\n",
    "                group=val,\n",
    "                metric_name=METRIC_NAME,\n",
    "                exceeds_flag=exceeds_flag,\n",
    "                threshold=threshold,\n",
    "            )\n",
    "        )\n",
    "        metric_vals.append(metric_val)\n",
    "        exceeds_thredhold.append(exceeds_flag)\n",
    "\n",
    "    result = pd.DataFrame(\n",
    "        {\n",
    "            \"Protected Feature\": df_col.name,\n",
    "            \"Metric\": METRIC_NAME,\n",
    "            \"Metric Value\": metric_vals,\n",
    "            \"Underpriviledged Group\": underpriviledged_group,\n",
    "            \"Threshold\": threshold,\n",
    "            \"Exceeds Threshold\": exceeds_thredhold,\n",
    "            \"Remarks\": remarks,\n",
    "        },\n",
    "        index=list(range(0, num_results)),\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Class Imbalance for 2 Classes\n",
    "\n",
    "In the example below, we compute the class imbalance on the feature **gender** for the risk group or the imbalanced group being **female**. The resulting value is close to 1, meaning that the risk group is highly imabalanced compared to the advantaged group, in this case, **males**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Feature</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underpriviledged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>class_imbalance</td>\n",
       "      <td>0.56</td>\n",
       "      <td>female</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Group female of Feature gender exceeded the cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Feature           Metric  Metric Value Underpriviledged Group  \\\n",
       "0            gender  class_imbalance          0.56                 female   \n",
       "\n",
       "   Threshold  Exceeds Threshold  \\\n",
       "0        0.5               True   \n",
       "\n",
       "                                             Remarks  \n",
       "0  Group female of Feature gender exceeded the cl...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_imbalance(df, protected_feature=\"gender\", underpriviledged_group=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Class Imbalance for Multiple Classes\n",
    "\n",
    "In the example below, we compute the class imbalance on the feature **location** without specifying a risk group. This means that the risk group is computed against all the other classes in the feature.\n",
    "\n",
    "**loc3** has the highest value among all the classes meaning it is highly imabalanced compared to other classes followed by **loc2**.\n",
    "\n",
    "**loc1** is balanced since 50% of the records are loc1 with the remaining 50% can either be loc2 or loc3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Feature</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underpriviledged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>class_imbalance</td>\n",
       "      <td>0.56</td>\n",
       "      <td>loc3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Group loc3 of Feature location exceeded the cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location</td>\n",
       "      <td>class_imbalance</td>\n",
       "      <td>0.14</td>\n",
       "      <td>loc1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location</td>\n",
       "      <td>class_imbalance</td>\n",
       "      <td>0.30</td>\n",
       "      <td>loc2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Feature           Metric  Metric Value Underpriviledged Group  \\\n",
       "0          location  class_imbalance          0.56                   loc3   \n",
       "1          location  class_imbalance          0.14                   loc1   \n",
       "2          location  class_imbalance          0.30                   loc2   \n",
       "\n",
       "   Threshold  Exceeds Threshold  \\\n",
       "0        0.5               True   \n",
       "1        0.5              False   \n",
       "2        0.5              False   \n",
       "\n",
       "                                             Remarks  \n",
       "0  Group loc3 of Feature location exceeded the cl...  \n",
       "1                                         Acceptable  \n",
       "2                                         Acceptable  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_imbalance(df, protected_feature=\"location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Demographic Disparity in Labels\n",
    "\n",
    "Conditional Demographic Disparity in Labels (CDDL) builds on Demographic Disparity to avoid Simpson's paradox by accounting for subgroup differences. The CDDL metric examines disparities within subgroups to provide a more nuanced understanding of potential bias.\n",
    "\n",
    "The formula for CDDL is:\n",
    "\n",
    "$$CDD = (1/n)*∑ᵢnᵢ*DDᵢ$$\n",
    "\n",
    "where:\n",
    "- n is the total number of observations\n",
    "- nᵢ is the number of observations in subgroup i\n",
    "- DDᵢ is the demographic disparity for subgroup i\n",
    "\n",
    "A classic example of why this conditional analysis is important comes from the Berkeley admissions case. While initial analysis showed men were accepted at higher rates overall (suggesting gender bias), examining admission rates by department revealed women actually had higher acceptance rates in many departments. The Simpson's paradox arose because women tended to apply to more competitive departments with lower overall acceptance rates.\n",
    "\n",
    "- Positive CDDL score indicates bias against the protected group\n",
    "- Zero indicates no disparity\n",
    "- Negative score indicates bias in favor of the protected group\n",
    "\n",
    "Document Source: [Conditional Demographic Disparity in Predicted Labels (CDDPL)](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-post-training-bias-metric-cddpl.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def compute_conditional_demographic_disparity_in_labels(\n",
    "    df: pd.DataFrame,\n",
    "    protected_attribute: str,\n",
    "    target: str,\n",
    "    group_variable: str,\n",
    "    protected_value: str,\n",
    "    positive_label: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the Conditional Demographic Disparity in Labels (CDDL) metric.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        Input DataFrame containing features and target\n",
    "    protected_attribute\n",
    "        Column name of protected attribute (e.g., 'sex', 'race')\n",
    "    target\n",
    "        Column name of target variable\n",
    "    group_variable\n",
    "        Column name for subgroup analysis (e.g., 'age_group', 'department')\n",
    "    protected_value\n",
    "        Value in protected_attribute that indicates protected group\n",
    "    positive_label\n",
    "        Value in target that indicates positive outcome\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the metric results with columns:\n",
    "        - feature: The protected attribute being analyzed\n",
    "        - metric: Name of the metric (CDDL)\n",
    "        - subgroup: The subgroup being analyzed\n",
    "        - subgroup_size: Number of observations in subgroup\n",
    "        - protected_rate: Rate for protected group\n",
    "        - unprotected_rate: Rate for unprotected group\n",
    "        - disparity: Disparity value for subgroup\n",
    "        - weight: Subgroup weight in final calculation\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    required_cols = {protected_attribute, target, group_variable}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        missing = required_cols - set(df.columns)\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    results = []\n",
    "    total_observations = len(df)\n",
    "    weighted_disparity_sum = 0\n",
    "\n",
    "    # Compute disparity for each subgroup\n",
    "    for subgroup in df[group_variable].unique():\n",
    "        # Subgroup mask\n",
    "        subgroup_mask = df[group_variable] == subgroup\n",
    "        subgroup_size = subgroup_mask.sum()\n",
    "\n",
    "        if subgroup_size == 0:\n",
    "            continue\n",
    "\n",
    "        # Protected group positive rate\n",
    "        protected_mask = df[protected_attribute] == protected_value\n",
    "        positive_mask = df[target] == positive_label\n",
    "\n",
    "        protected_positive = (protected_mask & positive_mask & subgroup_mask).sum()\n",
    "        protected_total = (protected_mask & subgroup_mask).sum()\n",
    "        protected_rate = (\n",
    "            protected_positive / protected_total if protected_total > 0 else 0.0\n",
    "        )\n",
    "\n",
    "        # Unprotected group positive rate\n",
    "        unprotected_positive = ((~protected_mask) & positive_mask & subgroup_mask).sum()\n",
    "        unprotected_total = ((~protected_mask) & subgroup_mask).sum()\n",
    "        unprotected_rate = (\n",
    "            unprotected_positive / unprotected_total if unprotected_total > 0 else 0.0\n",
    "        )\n",
    "\n",
    "        # Compute demographic disparity for subgroup\n",
    "        disparity = unprotected_rate - protected_rate\n",
    "        weight = subgroup_size / total_observations\n",
    "        weighted_disparity_sum += disparity * subgroup_size\n",
    "\n",
    "        # Store results\n",
    "        results.append(\n",
    "            {\n",
    "                \"feature\": protected_attribute,\n",
    "                \"subgroup\": subgroup,\n",
    "                \"subgroup_size\": int(subgroup_size),\n",
    "                \"protected_rate\": f\"{protected_rate:.2%}\",\n",
    "                \"unprotected_rate\": f\"{unprotected_rate:.2%}\",\n",
    "                \"disparity\": disparity,\n",
    "                \"weight\": weight,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Add overall score row\n",
    "    overall_score = weighted_disparity_sum / total_observations\n",
    "    overall_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"feature\": protected_attribute,\n",
    "                \"subgroup\": \"Overall\",\n",
    "                \"subgroup_size\": total_observations,\n",
    "                \"protected_rate\": \"-\",\n",
    "                \"unprotected_rate\": \"-\",\n",
    "                \"disparity\": overall_score,\n",
    "                \"weight\": 1.0,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pd.concat([results_df, overall_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Gender Bias in Loan Approvals by Age Group Example\n",
    "\n",
    "This example examines potential gender bias in loan approvals across different age categories using CDDL analysis. By grouping ages into categories, we can see if certain age ranges show different patterns of gender disparity in loan decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>protected_rate</th>\n",
       "      <th>unprotected_rate</th>\n",
       "      <th>disparity</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>18-30</td>\n",
       "      <td>338</td>\n",
       "      <td>28.21%</td>\n",
       "      <td>97.31%</td>\n",
       "      <td>0.691026</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>50+</td>\n",
       "      <td>200</td>\n",
       "      <td>23.40%</td>\n",
       "      <td>97.39%</td>\n",
       "      <td>0.739814</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>41-50</td>\n",
       "      <td>230</td>\n",
       "      <td>17.39%</td>\n",
       "      <td>97.28%</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>31-40</td>\n",
       "      <td>232</td>\n",
       "      <td>14.29%</td>\n",
       "      <td>99.47%</td>\n",
       "      <td>0.851880</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender</td>\n",
       "      <td>Overall</td>\n",
       "      <td>1000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.762915</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature subgroup  subgroup_size protected_rate unprotected_rate  disparity  \\\n",
       "0  gender    18-30            338         28.21%           97.31%   0.691026   \n",
       "1  gender      50+            200         23.40%           97.39%   0.739814   \n",
       "2  gender    41-50            230         17.39%           97.28%   0.798913   \n",
       "3  gender    31-40            232         14.29%           99.47%   0.851880   \n",
       "4  gender  Overall           1000              -                -   0.762915   \n",
       "\n",
       "   weight  \n",
       "0   0.338  \n",
       "1   0.200  \n",
       "2   0.230  \n",
       "3   0.232  \n",
       "4   1.000  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_biased_dataset(1000)\n",
    "\n",
    "# Create age groups for analysis\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"age\"], bins=[0, 30, 40, 50, 100], labels=[\"18-30\", \"31-40\", \"41-50\", \"50+\"]\n",
    ")\n",
    "\n",
    "compute_conditional_demographic_disparity_in_labels(\n",
    "    df=df,\n",
    "    protected_attribute=\"gender\",\n",
    "    target=\"target\",\n",
    "    group_variable=\"age_group\",\n",
    "    protected_value=\"female\",\n",
    "    positive_label=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows several key aspects of CDDL analysis:\n",
    "\n",
    "1. **Subgroup Distribution**:\n",
    "   - The data is split into four age groups: 18-30, 31-40, 41-50, and 50+\n",
    "   - Each group's size is indicated in the 'subgroup_size' column, showing the distribution of applicants across age ranges\n",
    "\n",
    "2. **Rate Comparison**:\n",
    "   - 'protected_rate' shows approval rates for females in each age group\n",
    "   - 'unprotected_rate' shows approval rates for males in each age group\n",
    "   - These rates help identify if disparities are consistent across age groups or if certain age groups show larger gaps\n",
    "\n",
    "3. **Disparity Measures**:\n",
    "   - Positive disparity values indicate higher approval rates for males\n",
    "   - The magnitude of disparity can vary across age groups\n",
    "   - The 'weight' column shows how much each age group contributes to the overall CDDL score\n",
    "\n",
    "4. **Overall Score**:\n",
    "   - The final row (\"Overall\") provides the weighted CDDL score across all age groups\n",
    "   - This score helps determine if there's systemic bias in the loan approval process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Simpson's Paradox in Location-based Analysis\n",
    "\n",
    "This example demonstrates how CDDL helps avoid Simpson's paradox by examining loan approvals across locations. While overall rates might suggest strong gender bias, examining rates by location reveals that the disparity varies significantly by area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>protected_rate</th>\n",
       "      <th>unprotected_rate</th>\n",
       "      <th>disparity</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>loc2</td>\n",
       "      <td>319</td>\n",
       "      <td>17.95%</td>\n",
       "      <td>95.85%</td>\n",
       "      <td>0.779019</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>loc1</td>\n",
       "      <td>460</td>\n",
       "      <td>39.66%</td>\n",
       "      <td>99.50%</td>\n",
       "      <td>0.598473</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>loc3</td>\n",
       "      <td>221</td>\n",
       "      <td>12.99%</td>\n",
       "      <td>96.53%</td>\n",
       "      <td>0.835408</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender</td>\n",
       "      <td>Overall</td>\n",
       "      <td>1000</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.708430</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature subgroup  subgroup_size protected_rate unprotected_rate  disparity  \\\n",
       "0  gender     loc2            319         17.95%           95.85%   0.779019   \n",
       "1  gender     loc1            460         39.66%           99.50%   0.598473   \n",
       "2  gender     loc3            221         12.99%           96.53%   0.835408   \n",
       "3  gender  Overall           1000              -                -   0.708430   \n",
       "\n",
       "   weight  \n",
       "0   0.319  \n",
       "1   0.460  \n",
       "2   0.221  \n",
       "3   1.000  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_conditional_demographic_disparity_in_labels(\n",
    "    df=df,\n",
    "    protected_attribute=\"gender\",\n",
    "    target=\"target\",\n",
    "    group_variable=\"location\",\n",
    "    protected_value=\"female\",\n",
    "    positive_label=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the CDDL analysis across different locations, revealing:\n",
    "\n",
    "1. **Location Distribution**:\n",
    "  - Each location's proportion of the total data is shown in the 'weight' column\n",
    "\n",
    "2. **Rate Comparison**:\n",
    "  - 'protected_rate' shows female approval rates by location\n",
    "  - 'unprotected_rate' shows male approval rates by location\n",
    "  - The variation in rates across locations demonstrates the Simpson's paradox effect\n",
    "\n",
    "3. **Disparity Measures**:\n",
    "  - Each location has its own disparity score\n",
    "  - Differences in disparities across locations suggest that bias isn't uniform\n",
    "\n",
    "4. **Overall Score**:\n",
    "  - The weighted CDDL score provides a balanced measure accounting for location differences\n",
    "  - This helps avoid misleading conclusions from aggregated data alone\n",
    "\n",
    "This location-based analysis helps identify whether apparent gender bias might be influenced by location-specific factors, demonstrating the importance of conditional analysis in fairness metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Parity Difference\n",
    "\n",
    "The Statistical Parity Difference (SPD) metric calculates the difference in the ratio of favorable outcomes between two groups, **monitored or unprivileged groups** and **reference or privileged groups**. A favorable outcome is the proportion of individuals in a group that receive a positive outcome (e.g., being approved for a loan). It is often used to assess the fairness of a decision-making process or outcome where there are two groups of interest, such as men and women or people of different racial groups.\n",
    "\n",
    "The formula for the difference according to Ruiviera:\n",
    "\n",
    "$$SPD = p(ŷ = 1|D_u) - p(ŷ = 1|D_p)$$\n",
    "\n",
    "Where $ŷ = 1$ is the favourable outcome and $D_u, D_p$ are respectively the unprivileged and privileged group data.\n",
    "\n",
    "Another way to look at the formula according to Data Platform:\n",
    "\n",
    "$$SPD = (np_u / np_p) - (ni_u / ni_p)$$\n",
    "\n",
    "Where $np_u, np_p$ are respectively the number of positive outcomes for the underprivileged and privileged groups. While $ni_u, ni_p$ are the number of instances or total number of members in each of the groups.\n",
    "\n",
    "**Note:** One key difference between SPD and other statistical parity method is that it is specifically designed to compare the fairness of only two groups.\n",
    "\n",
    "- An SPD of 0 indicates perfect fairness, meaning both groups have the same favorable outcome.\n",
    "- A positive SPD indicates that the unprivileged group has a higher favorable outcome than the privileged group.\n",
    "- A negative SPD indicates that the unprivileged group has a lower favorable outcome than the privileged group.\n",
    "\n",
    "Document Source: [Data Platform][Data Platform]<br>\n",
    "Code Inspiration: [Ruivieira][Ruivieira]\n",
    "\n",
    "[Data Platform]: https://dataplatform.cloud.ibm.com/docs/content/wsj/model/wos-stat-parity-diff.html?context=cpdaas\n",
    "[Ruivieira]: https://ruivieira.dev/fairness-in-machine-learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def compute_statistical_parity_diff(\n",
    "    num_pos_under: int, num_pos_priv: int, num_inst_under: int, num_inst_priv: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute statistical parity difference.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_pos_under\n",
    "        number of positive outcomes for the underprivileged class\n",
    "    num_pos_priv\n",
    "        number of positive outcomes for the privileged class\n",
    "    num_inst_under\n",
    "        total number of instances for the underprivileged class\n",
    "    num_inst_priv\n",
    "        total number of instances for the privileged class\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    statistical_imbalance_difference\n",
    "        The statistical parity difference metric\n",
    "    \"\"\"\n",
    "    metric_value = (num_pos_under / num_pos_priv) - (num_inst_under / num_inst_priv)\n",
    "    return \"%.2f\" % metric_value\n",
    "\n",
    "\n",
    "def statistical_parity_difference(\n",
    "    df_col: pd.Series,\n",
    "    pos_col: pd.Series,\n",
    "    pos_outcome_val,\n",
    "    privileged_group: str,\n",
    "    underprivileged_group: str = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute statistical parity difference given a pandas series containing a categorical feature column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_col\n",
    "        the feature column with the privileged and underpivileged class\n",
    "    pos_col\n",
    "        the column to determine whether a given row has a positive outcome or not\n",
    "    pos_outcome_val\n",
    "        the value to determine if an outcome is positive or not\n",
    "    underprivileged_group\n",
    "        the underpivileged class\n",
    "    privileged_group\n",
    "        the privileged class\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The statistical parity difference metric\n",
    "    \"\"\"\n",
    "    if underprivileged_group:\n",
    "        num_results = len([underprivileged_group])\n",
    "        num_class = df_col.value_counts().to_dict()\n",
    "\n",
    "        num_inst_priv = num_class[privileged_group]\n",
    "        num_pos_priv = df_col[\n",
    "            (pos_col == pos_outcome_val) & (df_col == privileged_group)\n",
    "        ].count()\n",
    "        num_inst_under = num_class[underprivileged_group]\n",
    "        num_pos_under = df_col[\n",
    "            (pos_col == pos_outcome_val) & (df_col == underprivileged_group)\n",
    "        ].count()\n",
    "\n",
    "        underprivileged_groups = [underprivileged_group]\n",
    "        metric_vals = compute_statistical_parity_diff(\n",
    "            num_pos_under=num_pos_under,\n",
    "            num_pos_priv=num_pos_priv,\n",
    "            num_inst_under=num_inst_under,\n",
    "            num_inst_priv=num_inst_priv,\n",
    "        )\n",
    "\n",
    "    elif underprivileged_group is None:\n",
    "        num_class = df_col.value_counts().to_dict()\n",
    "\n",
    "        num_inst_priv = num_class[privileged_group]\n",
    "        num_pos_priv = df_col[\n",
    "            (pos_col == pos_outcome_val) & (df_col == privileged_group)\n",
    "        ].count()\n",
    "\n",
    "        del num_class[privileged_group]\n",
    "        num_results = len(num_class)\n",
    "\n",
    "        underprivileged_groups = []\n",
    "        metric_vals = []\n",
    "        for key in num_class:\n",
    "            underprivileged_groups.append(key)\n",
    "\n",
    "            num_inst_under = num_class[key]\n",
    "            num_pos_under = df_col[\n",
    "                (pos_col == pos_outcome_val) & (df_col == key)\n",
    "            ].count()\n",
    "\n",
    "            metric_val = compute_statistical_parity_diff(\n",
    "                num_pos_under=num_pos_under,\n",
    "                num_pos_priv=num_pos_priv,\n",
    "                num_inst_under=num_inst_under,\n",
    "                num_inst_priv=num_inst_priv,\n",
    "            )\n",
    "            metric_vals.append(metric_val)\n",
    "\n",
    "    result = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": df_col.name,\n",
    "            \"metric\": \"statistical_parity_difference\",\n",
    "            \"risk_group\": underprivileged_groups,\n",
    "            \"metric_value\": metric_vals,\n",
    "        },\n",
    "        index=list(range(0, num_results)),\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "In the example below, we compute the statistical parity difference on the feature **gender** for the underprivileged group being **female**. The **target** column will be used to determine how many from the underprivileged and privileged (in this case **male**) have a postivie outcome of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>metric</th>\n",
       "      <th>risk_group</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>statistical_parity_difference</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature                         metric risk_group metric_value\n",
       "0  gender  statistical_parity_difference     female        -0.20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col = df.gender\n",
    "pos_col = df.target\n",
    "statistical_parity_difference(\n",
    "    df_col=df_col,\n",
    "    pos_col=pos_col,\n",
    "    pos_outcome_val=1,\n",
    "    privileged_group=\"male\",\n",
    "    underprivileged_group=\"female\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "In the example below, we compute the statistical parity difference on the feature **gender** with the underprivileged group **unspecified**. The **target** column will be used to determine how many from the underprivileged and privileged (in this case **male**) have a postivie outcome of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>metric</th>\n",
       "      <th>risk_group</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>statistical_parity_difference</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature                         metric risk_group metric_value\n",
       "0  gender  statistical_parity_difference     female        -0.20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col = df.gender\n",
    "pos_col = df.target\n",
    "statistical_parity_difference(\n",
    "    df_col=df_col, pos_col=pos_col, pos_outcome_val=1, privileged_group=\"male\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparate Impact\n",
    "\n",
    "**Disparate Impact (DI)** is a metric used to assess if outcomes differs across different groups or classes even if there are no intentional bias. It compares the proportion of individuals receiving favorable outcomes from ML predictions between two groups - a *privileged* (or *majority*) group and an *unprivileged* or (*minority*) group. Disparate Impact is calculated as the ratio of of favorable outcomes for the unprivileged group over the favorable outcomes for the privileged group.\n",
    "\n",
    "The formula for Disparate Impact (DI) is shown below:\n",
    "\n",
    "$$\n",
    "DI = \\frac{\\text{P}(\\text{favorable} = 1 \\mid \\text{C} = \\text{unprivileged})}{\\text{P}(\\text{favorable} = 1 \\mid \\text{C} = \\text{privileged})}\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$\\text{P}(\\text{favorable} = 1 \\mid \\text{C} = \\text{unprivileged})$ represents the proportion of favorable outcomes for the unprivileged group\n",
    "\n",
    "$\\text{P}(\\text{favorable} = 1 \\mid \\text{C} = \\text{privileged})$ represents the proportion of favorable outcomes for the privileged group\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "The formula could also be written below which illustrates how the proportion or rates are determined:\n",
    "\n",
    "$$\n",
    "DI = \\frac{\\#\\text{ favorable outcomes for unprivileged group} \\,\\div\\,\\#\\text{ unprivileged group}}{\\#\\text{ favorable outcomes for privileged group}\\,\\div\\,\\#\\text{ privileged group}}\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "To compute the Disparate Impact metric in GRAIL, use the `compute_disparate_impact` function. The function requires a pandas DataFrame `df` that has the column features containing the privileged and unprivileged groups (`protected_feature`), and the prediction columns that contains the predictions of a model (`target_col`) whose favorable prediction is equal to `positive_label` (defaults to 1). The function calculates the DI metric of a group `underprivileged_group` to all other groups. If `underprivileged_group` is not provided, then it will iterate and calculate the DI metrics for each unique groups with respect to the other groups. The function has a lower threshold (`threshold_lower`) and an upper threshold (`threshold_upper`) arguments whose default values are 0.8 and 1.2, respectively. The DI metric is deemed acceptable if it is within the threshold range. See the examples below for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def compute_disparate_impact(\n",
    "    df: pd.DataFrame,\n",
    "    protected_feature: str,\n",
    "    target_col: str,\n",
    "    underprivileged_group: str = None,\n",
    "    positive_label: int = 1,\n",
    "    threshold_upper: float = 1.2,\n",
    "    threshold_lower: float = 0.8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes the Disparate Impact (DI) metric for a given dataset and underprivileged group\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        The pandas DataFrame containing the privileged and unprivileged groups and\n",
    "        the output predictions\n",
    "    protected_feature\n",
    "        The column name of the protected feature where the underprivileged group is found\n",
    "    target_col\n",
    "        The column name of the predictions\n",
    "    positive_label\n",
    "        The positive label value in target_col. Defaults to 1\n",
    "    threshold_upper\n",
    "        Upper threshold for Disparate Impact. Defaults to 1.2\n",
    "    threshold_lower\n",
    "        Lower threshold for Disparat Impact. Defaults to 0.8\n",
    "    underprivileged_group\n",
    "        (Optional) The underprivileged group to calculate the DI metric for. If not provided,\n",
    "        the function calculates the DI metric for all groups\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The Disparate Impact metric\n",
    "    \"\"\"\n",
    "    METRIC_NAME = \"disparate_impact\"\n",
    "\n",
    "    # Check for required columns\n",
    "    if protected_feature not in df.columns:\n",
    "        raise ValueError(f\"Column '{protected_feature}' not in 'df'\")\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{target_col}' not in 'df'\")\n",
    "\n",
    "    # Check for valid values\n",
    "    if positive_label not in df[target_col].unique():\n",
    "        raise ValueError(\n",
    "            f\"Value '{positive_label}' not in column '{target_col}' of 'df'\"\n",
    "        )\n",
    "    if (\n",
    "        underprivileged_group\n",
    "        and underprivileged_group not in df[protected_feature].unique()\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Value '{underprivileged_group}' not in column '{target_col}' of 'df'\"\n",
    "        )\n",
    "\n",
    "    # Calculate the mean (rate), sum (total_positive), and count (total) for each group\n",
    "    group_stats = df.groupby(protected_feature)[target_col].agg(\n",
    "        rate=\"mean\", total_positive=\"sum\", total=\"count\"\n",
    "    )\n",
    "\n",
    "    # Calculate the Disparate Impact metrics for each group\n",
    "    disparate_impact_metrics = []\n",
    "\n",
    "    # If a specific underprivileged group is provided, calculate DI only for that group\n",
    "    if underprivileged_group:\n",
    "        current_rate = group_stats.loc[underprivileged_group, \"rate\"]\n",
    "\n",
    "        # Calculate the Disparate Impact metrics with respect to other groups\n",
    "        for group in group_stats.index:\n",
    "            if group != underprivileged_group:\n",
    "                group_rate = group_stats.loc[group, \"rate\"]\n",
    "                di_metric = current_rate / group_rate if group_rate != 0 else np.nan\n",
    "                exceeds_threshold = (\n",
    "                    di_metric < threshold_lower or di_metric > threshold_upper\n",
    "                )\n",
    "\n",
    "                disparate_impact_metrics.append(\n",
    "                    {\n",
    "                        \"Protected Faeture\": protected_feature,\n",
    "                        \"Metric\": METRIC_NAME,\n",
    "                        \"Metric Value\": di_metric,\n",
    "                        \"Underprivileged Group\": underprivileged_group,\n",
    "                        \"Privileged Group\": group,\n",
    "                        \"Threshold\": [threshold_lower, threshold_upper],\n",
    "                        \"Exceeds Threshold\": exceeds_threshold,\n",
    "                        \"Remarks\": remark_spiel_generator(\n",
    "                            feature_name=protected_feature,\n",
    "                            group=underprivileged_group,\n",
    "                            metric_name=METRIC_NAME,\n",
    "                            exceeds_flag=exceeds_threshold,\n",
    "                            lower_bound=threshold_lower,\n",
    "                            upper_bound=threshold_upper,\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Calculate the Disparate Impact metrics for combination of all other groups\n",
    "        if len(df[protected_feature].unique()) > 2:\n",
    "            other_total_positives = (\n",
    "                df[target_col].sum()\n",
    "                - group_stats.loc[underprivileged_group, \"total_positive\"]\n",
    "            )\n",
    "            other_total = len(df) - group_stats.loc[underprivileged_group, \"total\"]\n",
    "            other_rate = (\n",
    "                other_total_positives / other_total if other_total != 0 else np.nan\n",
    "            )\n",
    "\n",
    "            di_metric = current_rate / other_rate if other_rate != 0 else np.nan\n",
    "            exceeds_threshold = (\n",
    "                di_metric < threshold_lower or di_metric > threshold_upper\n",
    "            )\n",
    "\n",
    "            disparate_impact_metrics.append(\n",
    "                {\n",
    "                    \"Protected Faeture\": protected_feature,\n",
    "                    \"Metric\": METRIC_NAME,\n",
    "                    \"Metric Value\": di_metric,\n",
    "                    \"Underprivileged Group\": underprivileged_group,\n",
    "                    \"Privileged Group\": \"All\",\n",
    "                    \"Threshold\": [threshold_lower, threshold_upper],\n",
    "                    \"Exceeds Threshold\": exceeds_threshold,\n",
    "                    \"Remarks\": remark_spiel_generator(\n",
    "                        feature_name=protected_feature,\n",
    "                        group=underprivileged_group,\n",
    "                        metric_name=METRIC_NAME,\n",
    "                        exceeds_flag=exceeds_threshold,\n",
    "                        lower_bound=threshold_lower,\n",
    "                        upper_bound=threshold_upper,\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        for current_group in group_stats.index:\n",
    "            current_rate = group_stats.loc[current_group, \"rate\"]\n",
    "\n",
    "            # Calculate the Disparate Impact metrics with respect to other groups\n",
    "            for group in group_stats.index:\n",
    "                if group != current_group:\n",
    "                    group_rate = group_stats.loc[group, \"rate\"]\n",
    "\n",
    "                    di_metric = current_rate / group_rate if group_rate != 0 else np.nan\n",
    "                    exceeds_threshold = (\n",
    "                        di_metric < threshold_lower or di_metric > threshold_upper\n",
    "                    )\n",
    "\n",
    "                    disparate_impact_metrics.append(\n",
    "                        {\n",
    "                            \"Protected Faeture\": protected_feature,\n",
    "                            \"Metric\": METRIC_NAME,\n",
    "                            \"Metric Value\": di_metric,\n",
    "                            \"Underprivileged Group\": current_group,\n",
    "                            \"Privileged Group\": group,\n",
    "                            \"Threshold\": [threshold_lower, threshold_upper],\n",
    "                            \"Exceeds Threshold\": exceeds_threshold,\n",
    "                            \"Remarks\": remark_spiel_generator(\n",
    "                                feature_name=protected_feature,\n",
    "                                group=current_group,\n",
    "                                metric_name=METRIC_NAME,\n",
    "                                exceeds_flag=exceeds_threshold,\n",
    "                                lower_bound=threshold_lower,\n",
    "                                upper_bound=threshold_upper,\n",
    "                            ),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # Calculate the Disparate Impact metrics for combination of all other groups if more than 2 groups\n",
    "            if len(df[protected_feature].unique()) > 2:\n",
    "                other_total_positives = (\n",
    "                    df[target_col].sum()\n",
    "                    - group_stats.loc[current_group, \"total_positive\"]\n",
    "                )\n",
    "                other_total = len(df) - group_stats.loc[current_group, \"total\"]\n",
    "                other_rate = (\n",
    "                    other_total_positives / other_total if other_total != 0 else np.nan\n",
    "                )\n",
    "\n",
    "                di_metric = current_rate / other_rate if other_rate != 0 else np.nan\n",
    "                exceeds_threshold = (\n",
    "                    di_metric < threshold_lower or di_metric > threshold_upper\n",
    "                )\n",
    "\n",
    "                disparate_impact_metrics.append(\n",
    "                    {\n",
    "                        \"Protected Faeture\": protected_feature,\n",
    "                        \"Metric\": METRIC_NAME,\n",
    "                        \"Metric Value\": di_metric,\n",
    "                        \"Underprivileged Group\": current_group,\n",
    "                        \"Privileged Group\": \"All\",\n",
    "                        \"Threshold\": [threshold_lower, threshold_upper],\n",
    "                        \"Exceeds Threshold\": exceeds_threshold,\n",
    "                        \"Remarks\": remark_spiel_generator(\n",
    "                            feature_name=protected_feature,\n",
    "                            group=current_group,\n",
    "                            metric_name=METRIC_NAME,\n",
    "                            exceeds_flag=exceeds_threshold,\n",
    "                            lower_bound=threshold_lower,\n",
    "                            upper_bound=threshold_upper,\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(disparate_impact_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Disparate Impact for 2 Classes\n",
    "The example below illustrates how to compute the Disparate Impact metric on the protected feature `gender` having two classes with the underprivileged group, **female**, provided to argument `underprivileged_group`. The ML model's prediction results in `target` column was also provided to the `target_col` argument (default value of `positive_label` is 1). The function returns a pandas DataFrame containing the DI metric calculated for the provided underprivileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Faeture</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underprivileged Group</th>\n",
       "      <th>Privileged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>Group female of Feature gender exceeded the di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Faeture            Metric  Metric Value Underprivileged Group  \\\n",
       "0            gender  disparate_impact      0.205479                female   \n",
       "\n",
       "  Privileged Group   Threshold  Exceeds Threshold  \\\n",
       "0             male  [0.8, 1.2]               True   \n",
       "\n",
       "                                             Remarks  \n",
       "0  Group female of Feature gender exceeded the di...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_biased_dataset(100)\n",
    "\n",
    "compute_disparate_impact(\n",
    "    df=df,\n",
    "    protected_feature=\"gender\",\n",
    "    target_col=\"target\",\n",
    "    underprivileged_group=\"female\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `underprivileged_group` is not provided, it calculates the Disparate Impact metric for each group, considering each group as an unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Faeture</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underprivileged Group</th>\n",
       "      <th>Privileged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>Group female of Feature gender exceeded the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>True</td>\n",
       "      <td>Group male of Feature gender exceeded the disp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Faeture            Metric  Metric Value Underprivileged Group  \\\n",
       "0            gender  disparate_impact      0.205479                female   \n",
       "1            gender  disparate_impact      4.866667                  male   \n",
       "\n",
       "  Privileged Group   Threshold  Exceeds Threshold  \\\n",
       "0             male  [0.8, 1.2]               True   \n",
       "1           female  [0.8, 1.2]               True   \n",
       "\n",
       "                                             Remarks  \n",
       "0  Group female of Feature gender exceeded the di...  \n",
       "1  Group male of Feature gender exceeded the disp...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_disparate_impact(df=df, protected_feature=\"gender\", target_col=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Disparate Impact for Multiple Classes\n",
    "The following example calculates the Disparate Impact metric on a multi-class protected feature, `location`, with a given `underprivileged_group`. For more than 2 groups, it also calculates the DI metric of the unprivileged group against all the other groups combined and considered as a single privileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Faeture</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underprivileged Group</th>\n",
       "      <th>Privileged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.126749</td>\n",
       "      <td>loc1</td>\n",
       "      <td>loc2</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>loc1</td>\n",
       "      <td>loc3</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.102981</td>\n",
       "      <td>loc1</td>\n",
       "      <td>All</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Faeture            Metric  Metric Value Underprivileged Group  \\\n",
       "0          location  disparate_impact      1.126749                  loc1   \n",
       "1          location  disparate_impact      1.057143                  loc1   \n",
       "2          location  disparate_impact      1.102981                  loc1   \n",
       "\n",
       "  Privileged Group   Threshold  Exceeds Threshold     Remarks  \n",
       "0             loc2  [0.8, 1.2]              False  Acceptable  \n",
       "1             loc3  [0.8, 1.2]              False  Acceptable  \n",
       "2              All  [0.8, 1.2]              False  Acceptable  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_disparate_impact(\n",
    "    df=df,\n",
    "    protected_feature=\"location\",\n",
    "    target_col=\"target\",\n",
    "    underprivileged_group=\"loc1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `underprivileged_group` is not provided, then it calculates the DI metric for each unique group with respect to the other groups, as well as with all the groups combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected Faeture</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Metric Value</th>\n",
       "      <th>Underprivileged Group</th>\n",
       "      <th>Privileged Group</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Exceeds Threshold</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.126749</td>\n",
       "      <td>loc1</td>\n",
       "      <td>loc2</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>loc1</td>\n",
       "      <td>loc3</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.102981</td>\n",
       "      <td>loc1</td>\n",
       "      <td>All</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.887509</td>\n",
       "      <td>loc2</td>\n",
       "      <td>loc1</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.938224</td>\n",
       "      <td>loc2</td>\n",
       "      <td>loc3</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.901431</td>\n",
       "      <td>loc2</td>\n",
       "      <td>All</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>loc3</td>\n",
       "      <td>loc1</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>1.065844</td>\n",
       "      <td>loc3</td>\n",
       "      <td>loc2</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>location</td>\n",
       "      <td>disparate_impact</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>loc3</td>\n",
       "      <td>All</td>\n",
       "      <td>[0.8, 1.2]</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protected Faeture            Metric  Metric Value Underprivileged Group  \\\n",
       "0          location  disparate_impact      1.126749                  loc1   \n",
       "1          location  disparate_impact      1.057143                  loc1   \n",
       "2          location  disparate_impact      1.102981                  loc1   \n",
       "3          location  disparate_impact      0.887509                  loc2   \n",
       "4          location  disparate_impact      0.938224                  loc2   \n",
       "5          location  disparate_impact      0.901431                  loc2   \n",
       "6          location  disparate_impact      0.945946                  loc3   \n",
       "7          location  disparate_impact      1.065844                  loc3   \n",
       "8          location  disparate_impact      0.996528                  loc3   \n",
       "\n",
       "  Privileged Group   Threshold  Exceeds Threshold     Remarks  \n",
       "0             loc2  [0.8, 1.2]              False  Acceptable  \n",
       "1             loc3  [0.8, 1.2]              False  Acceptable  \n",
       "2              All  [0.8, 1.2]              False  Acceptable  \n",
       "3             loc1  [0.8, 1.2]              False  Acceptable  \n",
       "4             loc3  [0.8, 1.2]              False  Acceptable  \n",
       "5              All  [0.8, 1.2]              False  Acceptable  \n",
       "6             loc1  [0.8, 1.2]              False  Acceptable  \n",
       "7             loc2  [0.8, 1.2]              False  Acceptable  \n",
       "8              All  [0.8, 1.2]              False  Acceptable  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_disparate_impact(df=df, protected_feature=\"location\", target_col=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence\n",
    "\n",
    "KL Divergence measures how one probability distribution \n",
    "𝑄 differs from an expected distribution 𝑃, representing the \"information lost\" when 𝑄 approximates 𝑃. A value of zero means 𝑄 perfectly matches 𝑃, with higher values indicating more divergence. It’s asymmetric, so the KL Divergence of 𝑃 || 𝑄 is not the same as the KL Divergence of 𝑄 || 𝑃. In the context of fairness, KL Divergence can be used to determine which demographics have different target distributions relative to other demographics, which may need to be investigated for bias in training data.\n",
    "\n",
    "$$\n",
    "D_{KL}(P || Q) = \\sum_{i} P(i) \\log \\frac{P(i)}{Q(i)}\n",
    "$$\n",
    "\n",
    "or, in the continuous case:\n",
    "\n",
    "$$\n",
    "D_{KL}(P || Q) = \\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} \\, dx\n",
    "$$\n",
    "\n",
    "where:\n",
    "- P and Q are the two probability distributions.\n",
    "- p(x) and q(x) are the probability density functions of P and Q, respectively.\n",
    "\n",
    "In the context of GRAIL, the KL Divergence will be generated by comparing the probability distribution of the target variable for the entire dataset against the probability distribution of the target variable for specific categories of a feature. The higher the value of the KL Divergence, the larger the difference is between the target distribution of a specific demographic versus the target distribution of the rest of the dataset. This implies that the demographic group could have a relationship with the target that is different from other groups and might need to be investigated further (ex. people from loc1 could be more or less likely to get their loans rejected in training data).\n",
    "\n",
    "The function's output is a dataframe containing the KL Divergence value per category and a column to specify if the KL Divergence has exceeded the set threshold. For GRAIL, the default threshold is 0.20 but can be adjusted by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def compute_kl_divergence(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    protected_feature: str,\n",
    "    underprivileged_group: str = None,\n",
    "    threshold: float = 0.20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate Kullback-Leibler divergence between the overall target distribution\n",
    "    and a specified risk group's target distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe containing the target and risk feature columns.\n",
    "    target_col : str\n",
    "        The target variable column name.\n",
    "    protected_feature : str\n",
    "        The risk feature column name.\n",
    "    underprivileged_group : str, optional\n",
    "        The specific group to analyze within the risk feature. If None, KL Divergence will be calculated for all groups.\n",
    "    threshold : float, optional\n",
    "        The threshold for determining if the KL divergence exceeds a specified limit. Default is 0.20.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A dataframe containing the KL divergence results and threshold status.\n",
    "    \"\"\"\n",
    "    METRIC_NAME = \"KL Divergence\"\n",
    "    if underprivileged_group:\n",
    "        target_distribution = df[target_col].value_counts(normalize=True)\n",
    "        group_distribution = df[df[protected_feature] == underprivileged_group][\n",
    "            target_col\n",
    "        ].value_counts(normalize=True)\n",
    "        combined_index = target_distribution.index.union(group_distribution.index)\n",
    "        p = target_distribution.reindex(combined_index, fill_value=0)\n",
    "        q = group_distribution.reindex(combined_index, fill_value=0)\n",
    "        kl_divergence = entropy(p, q)\n",
    "        exceeds_flag = kl_divergence > threshold\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"target\": target_col,\n",
    "                \"protected_feature\": protected_feature,\n",
    "                \"underprivileged_group\": underprivileged_group,\n",
    "                \"kl_divergence\": kl_divergence,\n",
    "                \"threshold\": threshold,\n",
    "                \"exceeds\": exceeds_flag,\n",
    "                \"remarks\": remark_spiel_generator(\n",
    "                    feature_name=protected_feature,\n",
    "                    group=underprivileged_group,\n",
    "                    metric_name=METRIC_NAME,\n",
    "                    exceeds_flag=exceeds_flag,\n",
    "                    threshold=threshold,\n",
    "                ),  # f\"Group {underprivileged_group} of Feature {protected_feature} Exceeds KL Divergence Threshold of {threshold}\"\n",
    "                # if kl_divergence > threshold\n",
    "                # else \"Does Not Exceed Threshold\",\n",
    "            },\n",
    "            index=list(range(0, 1)),\n",
    "        )\n",
    "    else:\n",
    "        groups = df[protected_feature].unique()\n",
    "        kl_divs = []\n",
    "        exceeds = []\n",
    "        remarks = []\n",
    "        for risk_group in groups:\n",
    "            target_distribution = df[target_col].value_counts(normalize=True)\n",
    "            group_distribution = df[df[protected_feature] == risk_group][\n",
    "                target_col\n",
    "            ].value_counts(normalize=True)\n",
    "            combined_index = target_distribution.index.union(group_distribution.index)\n",
    "            p = target_distribution.reindex(combined_index, fill_value=0)\n",
    "            q = group_distribution.reindex(combined_index, fill_value=0)\n",
    "            kl_divergence = entropy(p, q)\n",
    "            kl_divs.append(kl_divergence)\n",
    "            exceeds_flag = kl_divergence > threshold\n",
    "            exceeds.append(exceeds_flag)\n",
    "            remarks.append(\n",
    "                remark_spiel_generator(\n",
    "                    feature_name=protected_feature,\n",
    "                    group=risk_group,\n",
    "                    metric_name=METRIC_NAME,\n",
    "                    exceeds_flag=exceeds_flag,\n",
    "                    threshold=threshold,\n",
    "                )\n",
    "            )\n",
    "            # remarks.append(\n",
    "            #     f\"Group {risk_group} of Feature {protected_feature} Exceeds KL Divergence Threshold of {threshold}\"\n",
    "            #     if kl_divergence > threshold\n",
    "            #     else \"Does Not Exceed Threshold\"\n",
    "            # )\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"target\": target_col,\n",
    "                \"risk_feature\": protected_feature,\n",
    "                \"risk_group\": groups,\n",
    "                \"kl_divergence\": kl_divs,\n",
    "                \"threshold\": threshold,\n",
    "                \"exceeds\": exceeds,\n",
    "                \"remarks\": remarks,\n",
    "            },\n",
    "            index=list(range(0, len(groups))),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing KL Divergence for 1 Category\n",
    "In this example, the target distribution of the full dataset is compared against the target distribution of females. The calculated KL divergence is 1.3, which is higher than the default threshold of 0.2. The data for females may then be investigated for potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>protected_feature</th>\n",
       "      <th>underprivileged_group</th>\n",
       "      <th>kl_divergence</th>\n",
       "      <th>threshold</th>\n",
       "      <th>exceeds</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.789931</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>Group female of Feature gender exceeded the KL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target protected_feature underprivileged_group  kl_divergence  threshold  \\\n",
       "0  target            gender                female       0.789931        0.2   \n",
       "\n",
       "   exceeds                                            remarks  \n",
       "0     True  Group female of Feature gender exceeded the KL...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_kl_divergence(df, \"target\", \"gender\", \"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing KL Divergence for Multiple Categories\n",
    "In the example below, we calculate KL Divergences for locations. All 3 KL Divergence values are under the default threshold, which implies that the target distributions for rows in loc1, loc2, or loc3 are consistent with the target distribution of the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>risk_feature</th>\n",
       "      <th>risk_group</th>\n",
       "      <th>kl_divergence</th>\n",
       "      <th>threshold</th>\n",
       "      <th>exceeds</th>\n",
       "      <th>remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>location</td>\n",
       "      <td>loc3</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target</td>\n",
       "      <td>location</td>\n",
       "      <td>loc1</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target</td>\n",
       "      <td>location</td>\n",
       "      <td>loc2</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target risk_feature risk_group  kl_divergence  threshold  exceeds  \\\n",
       "0  target     location       loc3       0.006715        0.2    False   \n",
       "1  target     location       loc1       0.017287        0.2    False   \n",
       "2  target     location       loc2       0.007069        0.2    False   \n",
       "\n",
       "      remarks  \n",
       "0  Acceptable  \n",
       "1  Acceptable  \n",
       "2  Acceptable  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_kl_divergence(df, \"target\", \"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

"""This module contains functions for computing fairness metrics for datasets."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../nbs/02_fairness_data_metrics.ipynb.

# %% auto 0
__all__ = ['compute_class_imbalance', 'class_imbalance', 'compute_conditional_demographic_disparity_in_labels',
           'compute_statistical_parity_diff', 'statistical_parity_difference', 'compute_disparate_impact',
           'compute_kl_divergence']

# %% ../../../nbs/02_fairness_data_metrics.ipynb 3
import pandas as pd
from scipy.stats import entropy
import numpy as np
from .utils import remark_spiel_generator

# %% ../../../nbs/02_fairness_data_metrics.ipynb 7
def compute_class_imbalance(num_class_adv: int, num_class_disadv: int) -> float:
    """
    Compute class imbalance.

    Parameters
    ----------
    num_class_adv
        number of records for the advantaged class
    num_class_disadv
        number of records for the disadvantaged class

    Returns
    -------
    class_imbalance_value
        The class imbalance metric
    """
    metric_value = (num_class_adv - num_class_disadv) / (
        num_class_adv + num_class_disadv
    )
    return metric_value


def class_imbalance(df: pd.DataFrame, protected_feature:str, underpriviledged_group: str = None, threshold: float = 0.5) -> pd.DataFrame:
    """
    Compute class imbalance given a pandas series containing a categorical feature column.

    Parameters
    ----------
    df_col
        the feature column with the advantaged and disadvantaged class
    underpriviledged_group
        optional. the disadvantaged class

    Returns
    -------
    pd.DataFrame
        The class imbalance metric
    """
    METRIC_NAME = "class_imbalance"
    df_col = df[protected_feature]
    if underpriviledged_group:
        underpriviledged_group = [underpriviledged_group]
    else:
        underpriviledged_group = df_col.unique()

    num_class = df_col.value_counts().to_dict()
    num_results = len(underpriviledged_group)
    metric_vals = []
    exceeds_thredhold = []
    remarks = []
    for val in underpriviledged_group:
        num_class_disadv = num_class[val]
        num_class_adv = len(df_col) - num_class_disadv
        metric_val = compute_class_imbalance(num_class_adv, num_class_disadv)
        exceeds_flag = True if metric_val > threshold or metric_val < -threshold else False
        remarks.append(remark_spiel_generator(feature_name=protected_feature, group=val, metric_name=METRIC_NAME, exceeds_flag=exceeds_flag, threshold=threshold))
        metric_vals.append(metric_val)
        exceeds_thredhold.append(exceeds_flag)
        
        

    result = pd.DataFrame(
        {
            "Protected Feature": df_col.name,
            "Metric": METRIC_NAME,
            "Metric Value": metric_vals,
            "Underpriviledged Group": underpriviledged_group,
            "Threshold": threshold,
            "Exceeds Threshold": exceeds_thredhold,
            "Remarks": remarks
        },
        index=list(range(0, num_results)),
    )

    return result

# %% ../../../nbs/02_fairness_data_metrics.ipynb 13
def compute_conditional_demographic_disparity_in_labels(
    df: pd.DataFrame,
    protected_attribute: str,
    target: str,
    group_variable: str,
    protected_value: str,
    positive_label: int,
) -> pd.DataFrame:
    """
    Compute the Conditional Demographic Disparity in Labels (CDDL) metric.

    Parameters
    ----------
    df
        Input DataFrame containing features and target
    protected_attribute
        Column name of protected attribute (e.g., 'sex', 'race')
    target
        Column name of target variable
    group_variable
        Column name for subgroup analysis (e.g., 'age_group', 'department')
    protected_value
        Value in protected_attribute that indicates protected group
    positive_label
        Value in target that indicates positive outcome

    Returns
    -------
    pd.DataFrame
        DataFrame containing the metric results with columns:
        - feature: The protected attribute being analyzed
        - metric: Name of the metric (CDDL)
        - subgroup: The subgroup being analyzed
        - subgroup_size: Number of observations in subgroup
        - protected_rate: Rate for protected group
        - unprotected_rate: Rate for unprotected group
        - disparity: Disparity value for subgroup
        - weight: Subgroup weight in final calculation
    """
    # Input validation
    required_cols = {protected_attribute, target, group_variable}
    if not required_cols.issubset(df.columns):
        missing = required_cols - set(df.columns)
        raise ValueError(f"Missing required columns: {missing}")

    results = []
    total_observations = len(df)
    weighted_disparity_sum = 0

    # Compute disparity for each subgroup
    for subgroup in df[group_variable].unique():
        # Subgroup mask
        subgroup_mask = df[group_variable] == subgroup
        subgroup_size = subgroup_mask.sum()

        if subgroup_size == 0:
            continue

        # Protected group positive rate
        protected_mask = df[protected_attribute] == protected_value
        positive_mask = df[target] == positive_label

        protected_positive = (protected_mask & positive_mask & subgroup_mask).sum()
        protected_total = (protected_mask & subgroup_mask).sum()
        protected_rate = (
            protected_positive / protected_total if protected_total > 0 else 0.0
        )

        # Unprotected group positive rate
        unprotected_positive = ((~protected_mask) & positive_mask & subgroup_mask).sum()
        unprotected_total = ((~protected_mask) & subgroup_mask).sum()
        unprotected_rate = (
            unprotected_positive / unprotected_total if unprotected_total > 0 else 0.0
        )

        # Compute demographic disparity for subgroup
        disparity = unprotected_rate - protected_rate
        weight = subgroup_size / total_observations
        weighted_disparity_sum += disparity * subgroup_size

        # Store results
        results.append(
            {
                "feature": protected_attribute,
                "subgroup": subgroup,
                "subgroup_size": int(subgroup_size),
                "protected_rate": f"{protected_rate:.2%}",
                "unprotected_rate": f"{unprotected_rate:.2%}",
                "disparity": disparity,
                "weight": weight,
            }
        )

    # Create results DataFrame
    results_df = pd.DataFrame(results)

    # Add overall score row
    overall_score = weighted_disparity_sum / total_observations
    overall_row = pd.DataFrame(
        [
            {
                "feature": protected_attribute,
                "subgroup": "Overall",
                "subgroup_size": total_observations,
                "protected_rate": "-",
                "unprotected_rate": "-",
                "disparity": overall_score,
                "weight": 1.0,
            }
        ]
    )

    return pd.concat([results_df, overall_row], ignore_index=True)

# %% ../../../nbs/02_fairness_data_metrics.ipynb 21
def compute_statistical_parity_diff(
    num_pos_under: int, num_pos_priv: int, num_inst_under: int, num_inst_priv: int
) -> float:
    """
    Compute statistical parity difference.

    Parameters
    ----------
    num_pos_under
        number of positive outcomes for the underprivileged class
    num_pos_priv
        number of positive outcomes for the privileged class
    num_inst_under
        total number of instances for the underprivileged class
    num_inst_priv
        total number of instances for the privileged class

    Returns
    -------
    statistical_imbalance_difference
        The statistical parity difference metric
    """
    metric_value = (num_pos_under / num_pos_priv) - (num_inst_under / num_inst_priv)
    return "%.2f" % metric_value


def statistical_parity_difference(
    df_col: pd.Series,
    pos_col: pd.Series,
    pos_outcome_val,
    privileged_group: str,
    underprivileged_group: str = None,
) -> pd.DataFrame:
    """
    Compute statistical parity difference given a pandas series containing a categorical feature column.

    Parameters
    ----------
    df_col
        the feature column with the privileged and underpivileged class
    pos_col
        the column to determine whether a given row has a positive outcome or not
    pos_outcome_val
        the value to determine if an outcome is positive or not
    underprivileged_group
        the underpivileged class
    privileged_group
        the privileged class

    Returns
    -------
    pd.DataFrame
        The statistical parity difference metric
    """
    if underprivileged_group:
        num_results = len([underprivileged_group])
        num_class = df_col.value_counts().to_dict()

        num_inst_priv = num_class[privileged_group]
        num_pos_priv = df_col[
            (pos_col == pos_outcome_val) & (df_col == privileged_group)
        ].count()
        num_inst_under = num_class[underprivileged_group]
        num_pos_under = df_col[
            (pos_col == pos_outcome_val) & (df_col == underprivileged_group)
        ].count()

        underprivileged_groups = [underprivileged_group]
        metric_vals = compute_statistical_parity_diff(
            num_pos_under=num_pos_under,
            num_pos_priv=num_pos_priv,
            num_inst_under=num_inst_under,
            num_inst_priv=num_inst_priv,
        )

    elif underprivileged_group is None:
        num_class = df_col.value_counts().to_dict()

        num_inst_priv = num_class[privileged_group]
        num_pos_priv = df_col[
            (pos_col == pos_outcome_val) & (df_col == privileged_group)
        ].count()

        del num_class[privileged_group]
        num_results = len(num_class)

        underprivileged_groups = []
        metric_vals = []
        for key in num_class:
            underprivileged_groups.append(key)

            num_inst_under = num_class[key]
            num_pos_under = df_col[
                (pos_col == pos_outcome_val) & (df_col == key)
            ].count()

            metric_val = compute_statistical_parity_diff(
                num_pos_under=num_pos_under,
                num_pos_priv=num_pos_priv,
                num_inst_under=num_inst_under,
                num_inst_priv=num_inst_priv,
            )
            metric_vals.append(metric_val)

    result = pd.DataFrame(
        {
            "feature": df_col.name,
            "metric": "statistical_parity_difference",
            "risk_group": underprivileged_groups,
            "metric_value": metric_vals,
        },
        index=list(range(0, num_results)),
    )

    return result

# %% ../../../nbs/02_fairness_data_metrics.ipynb 27
def compute_disparate_impact(
    df: pd.DataFrame, risk_group_col: str, prediction_col: str, risk_group: str = None
) -> pd.DataFrame:
    """
    Computes the Disparate Impact (DI) metrics for a given dataset and risk group

    Parameters
    ----------
    df
        The pandas DataFrame containing the privileged and unprivileged groups and
        the output predictions
    risk_group_col
        The feature column with the privileged and unprivileged groups
    prediction_col
        The column name of the predictions
    risk_group
        (Optional) The privileged group to calculate the DI metrics for. If not provided,
        the function calculates the DI metrics for all groups


    Returns
    -------
    pd.DataFrame
        The Disparate Impact metrics
    """
    # Check for required columns
    if risk_group_col not in df.columns:
        raise ValueError(f"Column '{risk_group_col}' not in 'df'")
    if prediction_col not in df.columns:
        raise ValueError(f"Column '{prediction_col}' not in 'df'")
    if risk_group and risk_group not in df[risk_group_col].unique():
        raise ValueError(
            f"Value '{risk_group}' not in column '{risk_group_col}' of 'df'"
        )

    # Check for valid values
    if not df[prediction_col].isin([0, 1]).all():
        raise ValueError(
            f"Column {prediction_col} should have binary values (0s and 1s)"
        )

    # Calculate the mean (rate), sum (total_positive), and count (total) for each group
    group_stats = df.groupby(risk_group_col)[prediction_col].agg(
        rate="mean", total_positive="sum", total="count"
    )

    # Calculate the Disparate Impact metrics for each group
    disparate_impact_metrics = []

    # If a specific risk group is provided, calculate DI only for that group
    if risk_group:
        current_rate = group_stats.loc[risk_group, "rate"]

        # Calculate the Disparate Impact metrics with respect to other groups
        for group in group_stats.index:
            if group != risk_group:
                group_rate = group_stats.loc[group, "rate"]
                di_metric = current_rate / group_rate if group_rate != 0 else np.nan

                disparate_impact_metrics.append(
                    {
                        "feature": risk_group_col,
                        "unprivileged_group": risk_group,
                        "privileged_group": group,
                        "metric": "Disparate Impact",
                        "metric_value": di_metric,
                    }
                )

        # Calculate the Disparate Impact metrics for combination of all other groups
        if len(df[risk_group_col].unique()) > 2:
            other_total_positives = (
                df[prediction_col].sum() - group_stats.loc[risk_group, "total_positive"]
            )
            other_total = len(df) - group_stats.loc[risk_group, "total"]
            other_rate = (
                other_total_positives / other_total if other_total != 0 else np.nan
            )

            di_metric = current_rate / other_rate if other_rate != 0 else np.nan

            disparate_impact_metrics.append(
                {
                    "feature": risk_group_col,
                    "unprivileged_group": risk_group,
                    "privileged_group": "All",
                    "metric": "Disparate Impact",
                    "metric_value": di_metric,
                }
            )
    else:
        for current_group in group_stats.index:
            current_rate = group_stats.loc[current_group, "rate"]

            # Calculate the Disparate Impact metrics with respect to other groups
            for group in group_stats.index:
                if group != current_group:
                    group_rate = group_stats.loc[group, "rate"]

                    di_metric = current_rate / group_rate if group_rate != 0 else np.nan

                    disparate_impact_metrics.append(
                        {
                            "feature": risk_group_col,
                            "unprivileged_group": current_group,
                            "privileged_group": group,
                            "metric": "Disparate Impact",
                            "metric_value": di_metric,
                        }
                    )

            # Calculate the Disparate Impact metrics for combination of all other groups if more than 2 groups
            if len(df[risk_group_col].unique()) > 2:
                other_total_positives = (
                    df[prediction_col].sum()
                    - group_stats.loc[current_group, "total_positive"]
                )
                other_total = len(df) - group_stats.loc[current_group, "total"]
                other_rate = (
                    other_total_positives / other_total if other_total != 0 else np.nan
                )

                di_metric = current_rate / other_rate if other_rate != 0 else np.nan

                disparate_impact_metrics.append(
                    {
                        "feature": risk_group_col,
                        "unprivileged_group": current_group,
                        "privileged_group": "All",
                        "metric": "Disparate Impact",
                        "metric_value": di_metric,
                    }
                )

    return pd.DataFrame(disparate_impact_metrics)

# %% ../../../nbs/02_fairness_data_metrics.ipynb 37
def compute_kl_divergence(
    df: pd.DataFrame,
    target_col: str,
    protected_feature: str,
    underprivileged_group: str = None,
    threshold: float = 0.20,
):
    """
    Calculate Kullback-Leibler divergence between the overall target distribution
    and a specified risk group's target distribution.

    Parameters
    ----------
    df : pandas.DataFrame
        The input dataframe containing the target and risk feature columns.
    target_col : str
        The target variable column name.
    protected_feature : str
        The risk feature column name.
    underprivileged_group : str, optional
        The specific group to analyze within the risk feature. If None, KL Divergence will be calculated for all groups.
    threshold : float, optional
        The threshold for determining if the KL divergence exceeds a specified limit. Default is 0.20.

    Returns
    -------
    pd.DataFrame
        A dataframe containing the KL divergence results and threshold status.
    """
    if underprivileged_group:
        target_distribution = df[target_col].value_counts(normalize=True)
        group_distribution = df[df[protected_feature] == underprivileged_group][
            target_col
        ].value_counts(normalize=True)
        combined_index = target_distribution.index.union(group_distribution.index)
        p = target_distribution.reindex(combined_index, fill_value=0)
        q = group_distribution.reindex(combined_index, fill_value=0)
        kl_divergence = entropy(p, q)
        return pd.DataFrame(
            {
                "target": target_col,
                "protected_feature": protected_feature,
                "underprivileged_group": underprivileged_group,
                "kl_divergence": kl_divergence,
                "threshold": threshold,
                "exceeds": kl_divergence > threshold,
                "remarks": f"Group {underprivileged_group} of Feature {protected_feature} Exceeds KL Divergence Threshold of {threshold}"
                if kl_divergence > threshold
                else "Does Not Exceed Threshold",
            },
            index=list(range(0, 1)),
        )
    else:
        groups = df[protected_feature].unique()
        kl_divs = []
        exceeds = []
        remarks = []
        for risk_group in groups:
            target_distribution = df[target_col].value_counts(normalize=True)
            group_distribution = df[df[protected_feature] == risk_group][
                target_col
            ].value_counts(normalize=True)
            combined_index = target_distribution.index.union(group_distribution.index)
            p = target_distribution.reindex(combined_index, fill_value=0)
            q = group_distribution.reindex(combined_index, fill_value=0)
            kl_divergence = entropy(p, q)
            kl_divs.append(kl_divergence)
            exceeds.append(kl_divergence > threshold)
            remarks.append(
                f"Group {risk_group} of Feature {protected_feature} Exceeds KL Divergence Threshold of {threshold}"
                if kl_divergence > threshold
                else "Does Not Exceed Threshold"
            )
        return pd.DataFrame(
            {
                "target": target_col,
                "risk_feature": protected_feature,
                "risk_group": groups,
                "kl_divergence": kl_divs,
                "threshold": threshold,
                "exceeds": exceeds,
                "remarks": remarks,
            },
            index=list(range(0, len(groups))),
        )
